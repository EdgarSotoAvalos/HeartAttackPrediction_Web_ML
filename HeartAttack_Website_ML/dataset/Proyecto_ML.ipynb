{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-14T20:54:30.048559Z","iopub.status.busy":"2023-06-14T20:54:30.048075Z","iopub.status.idle":"2023-06-14T20:54:30.076829Z","shell.execute_reply":"2023-06-14T20:54:30.075631Z","shell.execute_reply.started":"2023-06-14T20:54:30.048521Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import MinMaxScaler\n","\n","Heart= pd.read_csv('heart.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T20:43:38.288573Z","iopub.status.busy":"2023-06-14T20:43:38.288079Z","iopub.status.idle":"2023-06-14T20:43:38.320987Z","shell.execute_reply":"2023-06-14T20:43:38.319787Z","shell.execute_reply.started":"2023-06-14T20:43:38.288540Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trtbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalachh</th>\n","      <th>exng</th>\n","      <th>oldpeak</th>\n","      <th>slp</th>\n","      <th>caa</th>\n","      <th>thall</th>\n","      <th>output</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>63</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>145</td>\n","      <td>233</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>2.3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>130</td>\n","      <td>250</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>187</td>\n","      <td>0</td>\n","      <td>3.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>130</td>\n","      <td>204</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>1.4</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>120</td>\n","      <td>236</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>178</td>\n","      <td>0</td>\n","      <td>0.8</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>120</td>\n","      <td>354</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>163</td>\n","      <td>1</td>\n","      <td>0.6</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>140</td>\n","      <td>241</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>123</td>\n","      <td>1</td>\n","      <td>0.2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>299</th>\n","      <td>45</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>110</td>\n","      <td>264</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>132</td>\n","      <td>0</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>300</th>\n","      <td>68</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>144</td>\n","      <td>193</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>141</td>\n","      <td>0</td>\n","      <td>3.4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>301</th>\n","      <td>57</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>130</td>\n","      <td>131</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>115</td>\n","      <td>1</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>302</th>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>130</td>\n","      <td>236</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>174</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>303 rows Ã— 14 columns</p>\n","</div>"],"text/plain":["     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n","0     63    1   3     145   233    1        0       150     0      2.3    0   \n","1     37    1   2     130   250    0        1       187     0      3.5    0   \n","2     41    0   1     130   204    0        0       172     0      1.4    2   \n","3     56    1   1     120   236    0        1       178     0      0.8    2   \n","4     57    0   0     120   354    0        1       163     1      0.6    2   \n","..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n","298   57    0   0     140   241    0        1       123     1      0.2    1   \n","299   45    1   3     110   264    0        1       132     0      1.2    1   \n","300   68    1   0     144   193    1        1       141     0      3.4    1   \n","301   57    1   0     130   131    0        1       115     1      1.2    1   \n","302   57    0   1     130   236    0        0       174     0      0.0    1   \n","\n","     caa  thall  output  \n","0      0      1       1  \n","1      0      2       1  \n","2      0      2       1  \n","3      0      2       1  \n","4      0      2       1  \n","..   ...    ...     ...  \n","298    0      3       0  \n","299    0      3       0  \n","300    2      3       0  \n","301    1      3       0  \n","302    1      2       0  \n","\n","[303 rows x 14 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["Heart"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T20:45:50.282351Z","iopub.status.busy":"2023-06-14T20:45:50.281932Z","iopub.status.idle":"2023-06-14T20:45:50.297612Z","shell.execute_reply":"2023-06-14T20:45:50.296666Z","shell.execute_reply.started":"2023-06-14T20:45:50.282318Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Index(['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n","       'exng', 'oldpeak', 'slp', 'caa', 'thall', 'output'],\n","      dtype='object')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["Heart.columns"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T20:46:00.780037Z","iopub.status.busy":"2023-06-14T20:46:00.779597Z","iopub.status.idle":"2023-06-14T20:46:00.795444Z","shell.execute_reply":"2023-06-14T20:46:00.793640Z","shell.execute_reply.started":"2023-06-14T20:46:00.780006Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 303 entries, 0 to 302\n","Data columns (total 14 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   age       303 non-null    int64  \n"," 1   sex       303 non-null    int64  \n"," 2   cp        303 non-null    int64  \n"," 3   trtbps    303 non-null    int64  \n"," 4   chol      303 non-null    int64  \n"," 5   fbs       303 non-null    int64  \n"," 6   restecg   303 non-null    int64  \n"," 7   thalachh  303 non-null    int64  \n"," 8   exng      303 non-null    int64  \n"," 9   oldpeak   303 non-null    float64\n"," 10  slp       303 non-null    int64  \n"," 11  caa       303 non-null    int64  \n"," 12  thall     303 non-null    int64  \n"," 13  output    303 non-null    int64  \n","dtypes: float64(1), int64(13)\n","memory usage: 33.3 KB\n"]}],"source":["Heart.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["no hay valores faltantes en ninguna columna por lo cual no hay necesidad de imputar datos"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["METRICAS KNN SIN PREPROCESAR"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T18:39:24.363562Z","iopub.status.busy":"2023-06-14T18:39:24.362982Z","iopub.status.idle":"2023-06-14T18:39:25.931530Z","shell.execute_reply":"2023-06-14T18:39:25.930001Z","shell.execute_reply.started":"2023-06-14T18:39:24.363525Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------Ejecucion:   1 con k= 1 -------------\n","Exactitud: 0.7419354838709677\n","PrecisiÃ³n: 0.743421052631579\n","Sensibilidad: 0.7331932773109244\n","f1-score: 0.7350427350427351\n","-----------Ejecucion:   1 con k= 4 -------------\n","Exactitud: 0.6774193548387096\n","PrecisiÃ³n: 0.6901709401709402\n","Sensibilidad: 0.6869747899159664\n","f1-score: 0.6770833333333335\n","-----------Ejecucion:   1 con k= 7 -------------\n","Exactitud: 0.6451612903225806\n","PrecisiÃ³n: 0.641025641025641\n","Sensibilidad: 0.6386554621848739\n","f1-score: 0.6391534391534393\n","-----------Ejecucion:   2 con k= 1 -------------\n","Exactitud: 0.6451612903225806\n","PrecisiÃ³n: 0.64375\n","Sensibilidad: 0.6449579831932774\n","f1-score: 0.6436781609195403\n","-----------Ejecucion:   2 con k= 4 -------------\n","Exactitud: 0.6451612903225806\n","PrecisiÃ³n: 0.6644736842105263\n","Sensibilidad: 0.657563025210084\n","f1-score: 0.6436781609195403\n","-----------Ejecucion:   2 con k= 7 -------------\n","Exactitud: 0.7096774193548387\n","PrecisiÃ³n: 0.7083333333333333\n","Sensibilidad: 0.7100840336134454\n","f1-score: 0.7084639498432601\n","-----------Ejecucion:   3 con k= 1 -------------\n","Exactitud: 0.25806451612903225\n","PrecisiÃ³n: 0.25625\n","Sensibilidad: 0.2542016806722689\n","f1-score: 0.2549634273772205\n","-----------Ejecucion:   3 con k= 4 -------------\n","Exactitud: 0.5161290322580645\n","PrecisiÃ³n: 0.5210084033613445\n","Sensibilidad: 0.5210084033613445\n","f1-score: 0.5161290322580646\n","-----------Ejecucion:   3 con k= 7 -------------\n","Exactitud: 0.6129032258064516\n","PrecisiÃ³n: 0.6092436974789917\n","Sensibilidad: 0.6092436974789917\n","f1-score: 0.6092436974789917\n","-----------Ejecucion:   4 con k= 1 -------------\n","Exactitud: 0.6333333333333333\n","PrecisiÃ³n: 0.6294642857142857\n","Sensibilidad: 0.6312217194570136\n","f1-score: 0.6296296296296298\n","-----------Ejecucion:   4 con k= 4 -------------\n","Exactitud: 0.5333333333333333\n","PrecisiÃ³n: 0.5429864253393666\n","Sensibilidad: 0.5429864253393666\n","f1-score: 0.5333333333333333\n","-----------Ejecucion:   4 con k= 7 -------------\n","Exactitud: 0.7\n","PrecisiÃ³n: 0.7\n","Sensibilidad: 0.6809954751131222\n","f1-score: 0.6827262044653348\n","-----------Ejecucion:   5 con k= 1 -------------\n","Exactitud: 0.5666666666666667\n","PrecisiÃ³n: 0.5555555555555556\n","Sensibilidad: 0.5542986425339367\n","f1-score: 0.5542857142857144\n","-----------Ejecucion:   5 con k= 4 -------------\n","Exactitud: 0.6\n","PrecisiÃ³n: 0.6\n","Sensibilidad: 0.6018099547511313\n","f1-score: 0.5982142857142858\n","-----------Ejecucion:   5 con k= 7 -------------\n","Exactitud: 0.6666666666666666\n","PrecisiÃ³n: 0.6666666666666666\n","Sensibilidad: 0.6425339366515836\n","f1-score: 0.6411483253588517\n","-----------Ejecucion:   6 con k= 1 -------------\n","Exactitud: 0.5\n","PrecisiÃ³n: 0.49547511312217196\n","Sensibilidad: 0.4955357142857143\n","f1-score: 0.49494949494949503\n","-----------Ejecucion:   6 con k= 4 -------------\n","Exactitud: 0.5\n","PrecisiÃ³n: 0.49547511312217196\n","Sensibilidad: 0.4955357142857143\n","f1-score: 0.49494949494949503\n","-----------Ejecucion:   6 con k= 7 -------------\n","Exactitud: 0.5666666666666667\n","PrecisiÃ³n: 0.562200956937799\n","Sensibilidad: 0.5580357142857143\n","f1-score: 0.5542857142857143\n","-----------Ejecucion:   7 con k= 1 -------------\n","Exactitud: 0.6333333333333333\n","PrecisiÃ³n: 0.6339712918660287\n","Sensibilidad: 0.625\n","f1-score: 0.6228571428571429\n","-----------Ejecucion:   7 con k= 4 -------------\n","Exactitud: 0.7333333333333333\n","PrecisiÃ³n: 0.75\n","Sensibilidad: 0.7410714285714286\n","f1-score: 0.7321428571428572\n","-----------Ejecucion:   7 con k= 7 -------------\n","Exactitud: 0.7\n","PrecisiÃ³n: 0.6990950226244343\n","Sensibilidad: 0.6964285714285714\n","f1-score: 0.6969696969696969\n","-----------Ejecucion:   8 con k= 1 -------------\n","Exactitud: 0.7333333333333333\n","PrecisiÃ³n: 0.7784090909090908\n","Sensibilidad: 0.71875\n","f1-score: 0.7129186602870814\n","-----------Ejecucion:   8 con k= 4 -------------\n","Exactitud: 0.6666666666666666\n","PrecisiÃ³n: 0.6696428571428572\n","Sensibilidad: 0.6696428571428572\n","f1-score: 0.6666666666666666\n","-----------Ejecucion:   8 con k= 7 -------------\n","Exactitud: 0.7666666666666667\n","PrecisiÃ³n: 0.7669683257918551\n","Sensibilidad: 0.7633928571428572\n","f1-score: 0.7643097643097644\n","-----------Ejecucion:   9 con k= 1 -------------\n","Exactitud: 0.6333333333333333\n","PrecisiÃ³n: 0.6333333333333333\n","Sensibilidad: 0.6339285714285714\n","f1-score: 0.6329254727474972\n","-----------Ejecucion:   9 con k= 4 -------------\n","Exactitud: 0.5\n","PrecisiÃ³n: 0.5095693779904306\n","Sensibilidad: 0.5089285714285714\n","f1-score: 0.4949494949494949\n","-----------Ejecucion:   9 con k= 7 -------------\n","Exactitud: 0.5666666666666667\n","PrecisiÃ³n: 0.5723981900452488\n","Sensibilidad: 0.5714285714285714\n","f1-score: 0.5661846496106786\n","-----------Ejecucion:   10 con k= 1 -------------\n","Exactitud: 0.6\n","PrecisiÃ³n: 0.5972222222222223\n","Sensibilidad: 0.59375\n","f1-score: 0.5927601809954751\n","-----------Ejecucion:   10 con k= 4 -------------\n","Exactitud: 0.6666666666666666\n","PrecisiÃ³n: 0.7\n","Sensibilidad: 0.6785714285714286\n","f1-score: 0.6606334841628959\n","-----------Ejecucion:   10 con k= 7 -------------\n","Exactitud: 0.8\n","PrecisiÃ³n: 0.7991071428571428\n","Sensibilidad: 0.7991071428571428\n","f1-score: 0.7991071428571428\n","----------------Promedios\n","Promedios para k = 1\n","Exactitud: 0.594516129032258\n","PrecisiÃ³n: 0.5966851945354267\n","Sensibilidad: 0.5884837588881706\n","f1-situd: 0.6038709677419355\n","Preciscore: 0.5874010619091532\n","Promedios para k = 4\n","ExactiÃ³n: 0.6143326801337639\n","Sensibilidad: 0.6104092598577894\n","f1-score: 0.6017780143429967\n","Promedios para k = 7\n","Exactitud: 0.6734408602150538\n","PrecisiÃ³n: 0.6725038976761113\n","Sensibilidad: 0.6669905462184873\n","f1-score: 0.6661592584332874\n"]}],"source":["\n","\n","\n","X = Heart.drop('output', axis=1)  # Seleccionar todas las columnas excepto la columna 'target'\n","y = Heart['output'] \n","i=0\n","# Definir los valores de k\n","k_values = [1, 3, 7]\n","\n","# Inicializar listas para almacenar los valores de las mÃ©tricas para cada valor de k\n","accuracy_k1 = []\n","precision_k1 = []\n","recall_k1 = []\n","f1_k1 = []\n","accuracy_k4 = []\n","precision_k4 = []\n","recall_k4 = []\n","f1_k4 = []\n","accuracy_k7 = []\n","precision_k7 = []\n","recall_k7 = []\n","f1_k7 = []\n","\n","# Definir el objeto StratifiedKFold con 10 pliegues\n","skf = StratifiedKFold(n_splits=10)\n","\n","for train_index, test_index in skf.split(X, y):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    i=i+1\n","    # Iterar sobre los valores de k y entrenar un modelo para cada uno\n","    for k in k_values:\n","        # Definir el clasificador KNeighbors con el valor actual de k\n","        knn = KNeighborsClassifier(n_neighbors=k)\n","\n","        # Entrenar el modelo con el conjunto de entrenamiento\n","        knn.fit(X_train, y_train)\n","\n","        # Predecir las etiquetas objetivo del conjunto de prueba\n","        y_pred = knn.predict(X_test)\n","\n","        # calcular mÃ©tricas de evaluaciÃ³n\n","        accuracy = accuracy_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred, average='macro')\n","        recall = recall_score(y_test, y_pred, average='macro')\n","        f1 = f1_score(y_test, y_pred, average='macro')\n","\n","        # Agregar los valores a las listas correspondientes\n","        if k == 1:\n","            accuracy_k1.append(accuracy)\n","            precision_k1.append(precision)\n","            recall_k1.append(recall)\n","            f1_k1.append(f1)\n","        elif k == 4:\n","            accuracy_k4.append(accuracy)\n","            precision_k4.append(precision)\n","            recall_k4.append(recall)\n","            f1_k4.append(f1)\n","        else:\n","            accuracy_k7.append(accuracy)\n","            precision_k7.append(precision)\n","            recall_k7.append(recall)\n","            f1_k7.append(f1)\n","\n","        # imprimir resultados\n","        print(\"-----------Ejecucion:  \",i,\"con k=\",k,\"-------------\")\n","        print(\"Exactitud:\", accuracy)\n","        print(\"PrecisiÃ³n:\", precision)\n","        print(\"Sensibilidad:\", recall)\n","        print(\"f1-score:\", f1)\n","\n","# Calcular los promedios para cada valor de k\n","accuracy_k1_mean = np.mean(accuracy_k1)\n","precision_k1_mean = np.mean(precision_k1)\n","recall_k1_mean = np.mean(recall_k1)\n","f1_k1_mean = np.mean(f1_k1)\n","accuracy_k4_mean = np.mean(accuracy_k4)\n","precision_k4_mean = np.mean(precision_k4)\n","recall_k4_mean = np.mean(recall_k4)\n","f1_k4_mean = np.mean(f1_k4)\n","accuracy_k7_mean = np.mean(accuracy_k7)\n","precision_k7_mean = np.mean(precision_k7)\n","recall_k7_mean = np.mean(recall_k7)\n","f1_k7_mean = np.mean(f1_k7)\n","\n","print(\"----------------Promedios\")\n","print(\"Promedios para k = 1\")\n","print(\"Exactitud:\", accuracy_k1_mean)\n","print(\"PrecisiÃ³n:\", precision_k1_mean)\n","print(\"Sensibilidad:\", recall_k1_mean)\n","print(\"F1-score:\", f1_k1_mean)\n","\n","print(\"Promedios para k = 4\")\n","print(\"Exactitud:\", accuracy_k4_mean)\n","print(\"PrecisiÃ³n:\", precision_k4_mean)\n","print(\"Sensibilidad:\", recall_k4_mean)\n","print(\"F1-score:\", f1_k4_mean)\n","\n","print(\"Promedios para k = 7\")\n","print(\"Exactitud:\", accuracy_k7_mean)\n","print(\"PrecisiÃ³n:\", precision_k7_mean)\n","print(\"Sensibilidad:\", recall_k7_mean)\n","print(\"F1-score:\", f1_k7_mean)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["EDICION DE WILSON"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T20:41:35.343382Z","iopub.status.busy":"2023-06-14T20:41:35.342892Z","iopub.status.idle":"2023-06-14T20:41:35.579997Z","shell.execute_reply":"2023-06-14T20:41:35.578584Z","shell.execute_reply.started":"2023-06-14T20:41:35.343352Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[5, 17, 25, 26, 27, 28, 31, 34, 36, 37, 39, 40, 43, 50, 52, 55, 63, 70, 79, 83, 84, 94, 95, 96, 101, 112, 120, 136, 137, 138, 139, 146, 151, 152, 155, 158, 172, 173, 182, 185, 188, 196, 199, 200, 205, 206, 212, 213, 219, 220, 229, 230, 236, 238, 241, 245, 247, 257, 258, 259, 264, 265, 267, 273, 275, 281, 283, 286, 287, 290, 292, 294, 302]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>cp</th>\n","      <th>trtbps</th>\n","      <th>chol</th>\n","      <th>fbs</th>\n","      <th>restecg</th>\n","      <th>thalachh</th>\n","      <th>exng</th>\n","      <th>oldpeak</th>\n","      <th>slp</th>\n","      <th>caa</th>\n","      <th>thall</th>\n","      <th>output</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>63</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>145</td>\n","      <td>233</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>0</td>\n","      <td>2.3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>130</td>\n","      <td>250</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>187</td>\n","      <td>0</td>\n","      <td>3.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>130</td>\n","      <td>204</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>172</td>\n","      <td>0</td>\n","      <td>1.4</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>120</td>\n","      <td>236</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>178</td>\n","      <td>0</td>\n","      <td>0.8</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>120</td>\n","      <td>354</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>163</td>\n","      <td>1</td>\n","      <td>0.6</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>297</th>\n","      <td>59</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>164</td>\n","      <td>176</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>90</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>140</td>\n","      <td>241</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>123</td>\n","      <td>1</td>\n","      <td>0.2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>299</th>\n","      <td>45</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>110</td>\n","      <td>264</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>132</td>\n","      <td>0</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>300</th>\n","      <td>68</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>144</td>\n","      <td>193</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>141</td>\n","      <td>0</td>\n","      <td>3.4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>301</th>\n","      <td>57</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>130</td>\n","      <td>131</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>115</td>\n","      <td>1</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>230 rows Ã— 14 columns</p>\n","</div>"],"text/plain":["     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n","0     63    1   3     145   233    1        0       150     0      2.3    0   \n","1     37    1   2     130   250    0        1       187     0      3.5    0   \n","2     41    0   1     130   204    0        0       172     0      1.4    2   \n","3     56    1   1     120   236    0        1       178     0      0.8    2   \n","4     57    0   0     120   354    0        1       163     1      0.6    2   \n","..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n","297   59    1   0     164   176    1        0        90     0      1.0    1   \n","298   57    0   0     140   241    0        1       123     1      0.2    1   \n","299   45    1   3     110   264    0        1       132     0      1.2    1   \n","300   68    1   0     144   193    1        1       141     0      3.4    1   \n","301   57    1   0     130   131    0        1       115     1      1.2    1   \n","\n","     caa  thall  output  \n","0      0      1       1  \n","1      0      2       1  \n","2      0      2       1  \n","3      0      2       1  \n","4      0      2       1  \n","..   ...    ...     ...  \n","297    2      1       0  \n","298    0      3       0  \n","299    0      3       0  \n","300    2      3       0  \n","301    1      3       0  \n","\n","[230 rows x 14 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","from scipy.spatial.distance import cdist\n","#hacemos una copia del dataset original\n","data = Heart\n","#arreglo donde se guardaran los indices de los registros con valores atipicos\n","outliers = []\n","for j in range(len(data)):\n","    vecinos = 0\n","    # Obtener el registro actual del dataset\n","    registro_actual = data.iloc[j, :-1].values\n","    # Extraer las columnas del dataset\n","    dataset = data.iloc[:, :-1].values\n","    # Calcular las distancias entre el registro actual y los demÃ¡s registros del dataset\n","    distancias = cdist(registro_actual.reshape(1, -1), dataset)\n","    # Obtener las tres distancias mÃ¡s pequeÃ±as\n","    indices_mas_cercanos = np.argsort(distancias, axis=None)[:4]\n","    distancias_mas_cercanas = distancias[0, indices_mas_cercanos]\n","    l=0\n","    for l in range(3):\n","        aux = indices_mas_cercanos[l]\n","        if data['output'][j] != data['output'][aux]:\n","            vecinos += 1\n","        if vecinos >= 2:\n","            outliers.append(j)\n","print(outliers)\n","data=data.drop(outliers)\n","data\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["METRICAS QUITANDO OUTLIERS"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T20:47:28.688264Z","iopub.status.busy":"2023-06-14T20:47:28.687780Z","iopub.status.idle":"2023-06-14T20:47:29.105750Z","shell.execute_reply":"2023-06-14T20:47:29.104776Z","shell.execute_reply.started":"2023-06-14T20:47:28.688232Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------Ejecucion:   1 con k= 1 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9115384615384616\n","Sensibilidad: 0.9115384615384616\n","f1-score: 0.9115384615384616\n","-----------Ejecucion:   1 con k= 4 -------------\n","Exactitud: 0.782608695652174\n","PrecisiÃ³n: 0.7803030303030303\n","Sensibilidad: 0.7846153846153847\n","f1-score: 0.7809523809523811\n","-----------Ejecucion:   1 con k= 7 -------------\n","Exactitud: 0.7391304347826086\n","PrecisiÃ³n: 0.7416666666666667\n","Sensibilidad: 0.7230769230769231\n","f1-score: 0.726190476190476\n","-----------Ejecucion:   2 con k= 1 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9333333333333333\n","Sensibilidad: 0.9\n","f1-score: 0.9087301587301588\n","-----------Ejecucion:   2 con k= 4 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.8674242424242424\n","Sensibilidad: 0.8730769230769231\n","f1-score: 0.8685714285714285\n","-----------Ejecucion:   2 con k= 7 -------------\n","Exactitud: 0.782608695652174\n","PrecisiÃ³n: 0.8035714285714286\n","Sensibilidad: 0.7615384615384615\n","f1-score: 0.7667342799188641\n","-----------Ejecucion:   3 con k= 1 -------------\n","Exactitud: 0.782608695652174\n","PrecisiÃ³n: 0.7817460317460317\n","Sensibilidad: 0.773076923076923\n","f1-score: 0.7758284600389862\n","-----------Ejecucion:   3 con k= 4 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.823076923076923\n","Sensibilidad: 0.823076923076923\n","f1-score: 0.8230769230769232\n","-----------Ejecucion:   3 con k= 7 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.823076923076923\n","Sensibilidad: 0.823076923076923\n","f1-score: 0.8230769230769232\n","-----------Ejecucion:   4 con k= 1 -------------\n","Exactitud: 1.0\n","PrecisiÃ³n: 1.0\n","Sensibilidad: 1.0\n","f1-score: 1.0\n","-----------Ejecucion:   4 con k= 4 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9115384615384616\n","Sensibilidad: 0.9115384615384616\n","f1-score: 0.9115384615384616\n","-----------Ejecucion:   4 con k= 7 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.8375\n","Sensibilidad: 0.8115384615384615\n","f1-score: 0.8174603174603174\n","-----------Ejecucion:   5 con k= 1 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9115384615384616\n","Sensibilidad: 0.9115384615384616\n","f1-score: 0.9115384615384616\n","-----------Ejecucion:   5 con k= 4 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.8674242424242424\n","Sensibilidad: 0.8730769230769231\n","f1-score: 0.8685714285714285\n","-----------Ejecucion:   5 con k= 7 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.8375\n","Sensibilidad: 0.8115384615384615\n","f1-score: 0.8174603174603174\n","-----------Ejecucion:   6 con k= 1 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.873015873015873\n","Sensibilidad: 0.8615384615384616\n","f1-score: 0.8654970760233919\n","-----------Ejecucion:   6 con k= 4 -------------\n","Exactitud: 0.782608695652174\n","PrecisiÃ³n: 0.7817460317460317\n","Sensibilidad: 0.773076923076923\n","f1-score: 0.7758284600389862\n","-----------Ejecucion:   6 con k= 7 -------------\n","Exactitud: 0.7391304347826086\n","PrecisiÃ³n: 0.7416666666666667\n","Sensibilidad: 0.7230769230769231\n","f1-score: 0.726190476190476\n","-----------Ejecucion:   7 con k= 1 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.873015873015873\n","Sensibilidad: 0.8615384615384616\n","f1-score: 0.8654970760233919\n","-----------Ejecucion:   7 con k= 4 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9166666666666667\n","Sensibilidad: 0.9230769230769231\n","f1-score: 0.9128787878787878\n","-----------Ejecucion:   7 con k= 7 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.823076923076923\n","Sensibilidad: 0.823076923076923\n","f1-score: 0.8230769230769232\n","-----------Ejecucion:   8 con k= 1 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9333333333333333\n","Sensibilidad: 0.9\n","f1-score: 0.9087301587301588\n","-----------Ejecucion:   8 con k= 4 -------------\n","Exactitud: 0.7391304347826086\n","PrecisiÃ³n: 0.7346153846153847\n","Sensibilidad: 0.7346153846153847\n","f1-score: 0.7346153846153847\n","-----------Ejecucion:   8 con k= 7 -------------\n","Exactitud: 0.7391304347826086\n","PrecisiÃ³n: 0.7416666666666667\n","Sensibilidad: 0.7230769230769231\n","f1-score: 0.726190476190476\n","-----------Ejecucion:   9 con k= 1 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9166666666666667\n","Sensibilidad: 0.9230769230769231\n","f1-score: 0.9128787878787878\n","-----------Ejecucion:   9 con k= 4 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9166666666666667\n","Sensibilidad: 0.9230769230769231\n","f1-score: 0.9128787878787878\n","-----------Ejecucion:   9 con k= 7 -------------\n","Exactitud: 0.9565217391304348\n","PrecisiÃ³n: 0.9545454545454546\n","Sensibilidad: 0.9615384615384616\n","f1-score: 0.9561904761904763\n","-----------Ejecucion:   10 con k= 1 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9128787878787878\n","Sensibilidad: 0.9128787878787878\n","f1-score: 0.9128787878787878\n","-----------Ejecucion:   10 con k= 4 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9230769230769231\n","Sensibilidad: 0.9166666666666667\n","f1-score: 0.9128787878787878\n","-----------Ejecucion:   10 con k= 7 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.8373015873015872\n","Sensibilidad: 0.821969696969697\n","f1-score: 0.823076923076923\n","----------------Promedios\n","Promedios para k = 1\n","Exactitud: 0.9\n","PrecisiÃ³n: 0.904706682206682\n","Sensibilidad: 0.895518648018648\n","f1-situd: 0.8521739130434781\n","Preciscore: 0.8973117428380585\n","Promedios para k = 4\n","ExactiÃ³n: 0.8522538572538572\n","Sensibilidad: 0.8535897435897436\n","f1-score: 0.8501790831001358\n","Promedios para k = 7\n","Exactitud: 0.8086956521739129\n","PrecisiÃ³n: 0.8141572316572316\n","Sensibilidad: 0.7983508158508158\n","f1-score: 0.8005647588832174\n"]}],"source":["\n","X = data.drop('output', axis=1)  # Seleccionar todas las columnas excepto la columna 'target'\n","y = data['output'] \n","i=0\n","# Definir los valores de k\n","k_values = [1, 4, 7]\n","\n","# Inicializar listas para almacenar los valores de las mÃ©tricas para cada valor de k\n","accuracy_k1 = []\n","precision_k1 = []\n","recall_k1 = []\n","f1_k1 = []\n","accuracy_k4 = []\n","precision_k4 = []\n","recall_k4 = []\n","f1_k4 = []\n","accuracy_k7 = []\n","precision_k7 = []\n","recall_k7 = []\n","f1_k7 = []\n","\n","# Definir el objeto StratifiedKFold con 10 pliegues\n","skf = StratifiedKFold(n_splits=10)\n","\n","for train_index, test_index in skf.split(X, y):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    i=i+1\n","    # Iterar sobre los valores de k y entrenar un modelo para cada uno\n","    for k in k_values:\n","        # Definir el clasificador KNeighbors con el valor actual de k\n","        knn = KNeighborsClassifier(n_neighbors=k)\n","\n","        # Entrenar el modelo con el conjunto de entrenamiento\n","        knn.fit(X_train, y_train)\n","\n","        # Predecir las etiquetas objetivo del conjunto de prueba\n","        y_pred = knn.predict(X_test)\n","\n","        # calcular mÃ©tricas de evaluaciÃ³n\n","        accuracy = accuracy_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred, average='macro')\n","        recall = recall_score(y_test, y_pred, average='macro')\n","        f1 = f1_score(y_test, y_pred, average='macro')\n","\n","        # Agregar los valores a las listas correspondientes\n","        if k == 1:\n","            accuracy_k1.append(accuracy)\n","            precision_k1.append(precision)\n","            recall_k1.append(recall)\n","            f1_k1.append(f1)\n","        elif k == 4:\n","            accuracy_k4.append(accuracy)\n","            precision_k4.append(precision)\n","            recall_k4.append(recall)\n","            f1_k4.append(f1)\n","        else:\n","            accuracy_k7.append(accuracy)\n","            precision_k7.append(precision)\n","            recall_k7.append(recall)\n","            f1_k7.append(f1)\n","\n","        # imprimir resultados\n","        print(\"-----------Ejecucion:  \",i,\"con k=\",k,\"-------------\")\n","        print(\"Exactitud:\", accuracy)\n","        print(\"PrecisiÃ³n:\", precision)\n","        print(\"Sensibilidad:\", recall)\n","        print(\"f1-score:\", f1)\n","\n","# Calcular los promedios para cada valor de k\n","accuracy_k1_mean = np.mean(accuracy_k1)\n","precision_k1_mean = np.mean(precision_k1)\n","recall_k1_mean = np.mean(recall_k1)\n","f1_k1_mean = np.mean(f1_k1)\n","accuracy_k4_mean = np.mean(accuracy_k4)\n","precision_k4_mean = np.mean(precision_k4)\n","recall_k4_mean = np.mean(recall_k4)\n","f1_k4_mean = np.mean(f1_k4)\n","accuracy_k7_mean = np.mean(accuracy_k7)\n","precision_k7_mean = np.mean(precision_k7)\n","recall_k7_mean = np.mean(recall_k7)\n","f1_k7_mean = np.mean(f1_k7)\n","\n","print(\"----------------Promedios\")\n","print(\"Promedios para k = 1\")\n","print(\"Exactitud:\", accuracy_k1_mean)\n","print(\"PrecisiÃ³n:\", precision_k1_mean)\n","print(\"Sensibilidad:\", recall_k1_mean)\n","print(\"F1-score:\", f1_k1_mean)\n","\n","print(\"Promedios para k = 4\")\n","print(\"Exactitud:\", accuracy_k4_mean)\n","print(\"PrecisiÃ³n:\", precision_k4_mean)\n","print(\"Sensibilidad:\", recall_k4_mean)\n","print(\"F1-score:\", f1_k4_mean)\n","\n","print(\"Promedios para k = 7\")\n","print(\"Exactitud:\", accuracy_k7_mean)\n","print(\"PrecisiÃ³n:\", precision_k7_mean)\n","print(\"Sensibilidad:\", recall_k7_mean)\n","print(\"F1-score:\", f1_k7_mean)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["DATASET  NORMALIZADO"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T21:00:35.654567Z","iopub.status.busy":"2023-06-14T21:00:35.653746Z","iopub.status.idle":"2023-06-14T21:00:35.983660Z","shell.execute_reply":"2023-06-14T21:00:35.982318Z","shell.execute_reply.started":"2023-06-14T21:00:35.654522Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------Ejecucion: 10 con k = 1 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9333333333333333\n","Sensibilidad: 0.9\n","F1-score: 0.9087301587301588\n","-----------Ejecucion: 10 con k = 4 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9115384615384616\n","Sensibilidad: 0.9115384615384616\n","F1-score: 0.9115384615384616\n","-----------Ejecucion: 10 con k = 7 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.873015873015873\n","Sensibilidad: 0.8615384615384616\n","F1-score: 0.8654970760233919\n","-----------Ejecucion: 10 con k = 1 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.8674242424242424\n","Sensibilidad: 0.8730769230769231\n","F1-score: 0.8685714285714285\n","-----------Ejecucion: 10 con k = 4 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.823076923076923\n","Sensibilidad: 0.823076923076923\n","F1-score: 0.8230769230769232\n","-----------Ejecucion: 10 con k = 7 -------------\n","Exactitud: 0.782608695652174\n","PrecisiÃ³n: 0.7817460317460317\n","Sensibilidad: 0.773076923076923\n","F1-score: 0.7758284600389862\n","-----------Ejecucion: 10 con k = 1 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.8295454545454546\n","Sensibilidad: 0.8346153846153846\n","F1-score: 0.8257575757575757\n","-----------Ejecucion: 10 con k = 4 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.8846153846153846\n","Sensibilidad: 0.8846153846153846\n","F1-score: 0.8695652173913044\n","-----------Ejecucion: 10 con k = 7 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.8295454545454546\n","Sensibilidad: 0.8346153846153846\n","F1-score: 0.8257575757575757\n","-----------Ejecucion: 10 con k = 1 -------------\n","Exactitud: 0.7391304347826086\n","PrecisiÃ³n: 0.7416666666666667\n","Sensibilidad: 0.7230769230769231\n","F1-score: 0.726190476190476\n","-----------Ejecucion: 10 con k = 4 -------------\n","Exactitud: 0.9565217391304348\n","PrecisiÃ³n: 0.9642857142857143\n","Sensibilidad: 0.95\n","F1-score: 0.9551656920077973\n","-----------Ejecucion: 10 con k = 7 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9333333333333333\n","Sensibilidad: 0.9\n","F1-score: 0.9087301587301588\n","-----------Ejecucion: 10 con k = 1 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9115384615384616\n","Sensibilidad: 0.9115384615384616\n","F1-score: 0.9115384615384616\n","-----------Ejecucion: 10 con k = 4 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.8674242424242424\n","Sensibilidad: 0.8730769230769231\n","F1-score: 0.8685714285714285\n","-----------Ejecucion: 10 con k = 7 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.8674242424242424\n","Sensibilidad: 0.8730769230769231\n","F1-score: 0.8685714285714285\n","-----------Ejecucion: 10 con k = 1 -------------\n","Exactitud: 0.7391304347826086\n","PrecisiÃ³n: 0.7424242424242424\n","Sensibilidad: 0.7461538461538462\n","F1-score: 0.7386363636363636\n","-----------Ejecucion: 10 con k = 4 -------------\n","Exactitud: 0.782608695652174\n","PrecisiÃ³n: 0.8333333333333333\n","Sensibilidad: 0.8076923076923077\n","F1-score: 0.7809523809523811\n","-----------Ejecucion: 10 con k = 7 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.8846153846153846\n","Sensibilidad: 0.8846153846153846\n","F1-score: 0.8695652173913044\n","-----------Ejecucion: 10 con k = 1 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.823076923076923\n","Sensibilidad: 0.823076923076923\n","F1-score: 0.8230769230769232\n","-----------Ejecucion: 10 con k = 4 -------------\n","Exactitud: 0.782608695652174\n","PrecisiÃ³n: 0.7961538461538462\n","Sensibilidad: 0.7961538461538462\n","F1-score: 0.7826086956521738\n","-----------Ejecucion: 10 con k = 7 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.873015873015873\n","Sensibilidad: 0.8615384615384616\n","F1-score: 0.8654970760233919\n","-----------Ejecucion: 10 con k = 1 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9115384615384616\n","Sensibilidad: 0.9115384615384616\n","F1-score: 0.9115384615384616\n","-----------Ejecucion: 10 con k = 4 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.823076923076923\n","Sensibilidad: 0.823076923076923\n","F1-score: 0.8230769230769232\n","-----------Ejecucion: 10 con k = 7 -------------\n","Exactitud: 0.782608695652174\n","PrecisiÃ³n: 0.7803030303030303\n","Sensibilidad: 0.7846153846153847\n","F1-score: 0.7809523809523811\n","-----------Ejecucion: 10 con k = 1 -------------\n","Exactitud: 0.8260869565217391\n","PrecisiÃ³n: 0.8375\n","Sensibilidad: 0.8115384615384615\n","F1-score: 0.8174603174603174\n","-----------Ejecucion: 10 con k = 4 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.90625\n","Sensibilidad: 0.85\n","F1-score: 0.8600405679513184\n","-----------Ejecucion: 10 con k = 7 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.90625\n","Sensibilidad: 0.85\n","F1-score: 0.8600405679513184\n","-----------Ejecucion: 10 con k = 1 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.8712121212121212\n","Sensibilidad: 0.8712121212121212\n","F1-score: 0.8695652173913043\n","-----------Ejecucion: 10 con k = 4 -------------\n","Exactitud: 0.9130434782608695\n","PrecisiÃ³n: 0.9128787878787878\n","Sensibilidad: 0.9128787878787878\n","F1-score: 0.9128787878787878\n","-----------Ejecucion: 10 con k = 7 -------------\n","Exactitud: 0.8695652173913043\n","PrecisiÃ³n: 0.9\n","Sensibilidad: 0.8636363636363636\n","F1-score: 0.8654970760233919\n","----------------Promedios\n","Promedios para k = 1\n","Exactitud: 0.8434782608695652\n","PrecisiÃ³n: 0.8469259906759907\n","Sensibilidad: 0.8405827505827507\n","F1-score: 0.8401065383891471\n","Promedios para k = 4\n","Exactitud: 0.8608695652173914\n","PrecisiÃ³n: 0.8722633616383616\n","Sensibilidad: 0.8632109557109556\n","F1-score: 0.85874750780975\n","Promedios para k = 7\n","Exactitud: 0.8521739130434783\n","PrecisiÃ³n: 0.8629249222999222\n","Sensibilidad: 0.8486713286713286\n","F1-score: 0.848593701746333\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Cargar el dataset desde un archivo CSV\n","\n","\n","# Separar las caracterÃ­sticas (X) y las etiquetas (y)\n","X = data.drop('output', axis=1)\n","y = data['output']\n","\n","# Normalizar los datos\n","scaler = MinMaxScaler() #Transforma los datos para que se encuentren entre 0 y 1\n","X = scaler.fit_transform(X)\n","\n","# Definir los valores de k\n","k_values = [1, 4, 7]\n","\n","# Inicializar listas para almacenar los valores de las mÃ©tricas para cada valor de k\n","accuracy_k1 = []\n","precision_k1 = []\n","recall_k1 = []\n","f1_k1 = []\n","accuracy_k4 = []\n","precision_k4 = []\n","recall_k4 = []\n","f1_k4 = []\n","accuracy_k7 = []\n","precision_k7 = []\n","recall_k7 = []\n","f1_k7 = []\n","\n","# Definir el objeto StratifiedKFold con 10 pliegues\n","skf = StratifiedKFold(n_splits=10)\n","\n","for train_index, test_index in skf.split(X, y):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    \n","    # Iterar sobre los valores de k y entrenar un modelo para cada uno\n","    for k in k_values:\n","        # Definir el clasificador KNeighbors con el valor actual de k\n","        knn = KNeighborsClassifier(n_neighbors=k)\n","\n","        # Entrenar el modelo con el conjunto de entrenamiento\n","        knn.fit(X_train, y_train)\n","\n","        # Predecir las etiquetas objetivo del conjunto de prueba\n","        y_pred = knn.predict(X_test)\n","\n","        # Calcular mÃ©tricas de evaluaciÃ³n\n","        accuracy = accuracy_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred, average='macro')\n","        recall = recall_score(y_test, y_pred, average='macro')\n","        f1 = f1_score(y_test, y_pred, average='macro')\n","\n","        # Agregar los valores a las listas correspondientes\n","        if k == 1:\n","            accuracy_k1.append(accuracy)\n","            precision_k1.append(precision)\n","            recall_k1.append(recall)\n","            f1_k1.append(f1)\n","        elif k == 4:\n","            accuracy_k4.append(accuracy)\n","            precision_k4.append(precision)\n","            recall_k4.append(recall)\n","            f1_k4.append(f1)\n","        else:\n","            accuracy_k7.append(accuracy)\n","            precision_k7.append(precision)\n","            recall_k7.append(recall)\n","            f1_k7.append(f1)\n","\n","        # Imprimir resultados\n","        print(\"-----------Ejecucion:\", i, \"con k =\", k, \"-------------\")\n","        print(\"Exactitud:\", accuracy)\n","        print(\"PrecisiÃ³n:\", precision)\n","        print(\"Sensibilidad:\", recall)\n","        print(\"F1-score:\", f1)\n","\n","# Calcular los promedios para cada valor de k\n","accuracy_k1_mean = np.mean(accuracy_k1)\n","precision_k1_mean = np.mean(precision_k1)\n","recall_k1_mean = np.mean(recall_k1)\n","f1_k1_mean = np.mean(f1_k1)\n","accuracy_k4_mean = np.mean(accuracy_k4)\n","precision_k4_mean = np.mean(precision_k4)\n","recall_k4_mean = np.mean(recall_k4)\n","f1_k4_mean = np.mean(f1_k4)\n","accuracy_k7_mean = np.mean(accuracy_k7)\n","precision_k7_mean = np.mean(precision_k7)\n","recall_k7_mean = np.mean(recall_k7)\n","f1_k7_mean = np.mean(f1_k7)\n","\n","print(\"----------------Promedios\")\n","print(\"Promedios para k = 1\")\n","print(\"Exactitud:\", accuracy_k1_mean)\n","print(\"PrecisiÃ³n:\", precision_k1_mean)\n","print(\"Sensibilidad:\", recall_k1_mean)\n","print(\"F1-score:\", f1_k1_mean)\n","\n","print(\"Promedios para k = 4\")\n","print(\"Exactitud:\", accuracy_k4_mean)\n","print(\"PrecisiÃ³n:\", precision_k4_mean)\n","print(\"Sensibilidad:\", recall_k4_mean)\n","print(\"F1-score:\", f1_k4_mean)\n","\n","print(\"Promedios para k = 7\")\n","print(\"Exactitud:\", accuracy_k7_mean)\n","print(\"PrecisiÃ³n:\", precision_k7_mean)\n","print(\"Sensibilidad:\", recall_k7_mean)\n","print(\"F1-score:\", f1_k7_mean)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Sacando db nomrmalizado sin outliers"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------Promedios\n","Promedios para k = 1\n","Exactitud: 0.7689247311827957\n","PrecisiÃ³n: 0.7786317404216011\n","Sensibilidad: 0.7662895927601809\n","F1-score: 0.7646666652086396\n","Promedios para k = 4\n","Exactitud: 0.8179569892473119\n","PrecisiÃ³n: 0.8269727249874309\n","Sensibilidad: 0.8208548804137038\n","F1-score: 0.8160118817216164\n","Promedios para k = 7\n","Exactitud: 0.8116129032258066\n","PrecisiÃ³n: 0.8157230841054369\n","Sensibilidad: 0.8108496283128636\n","F1-score: 0.8090785831191838\n"]}],"source":["X = Heart.drop('output', axis=1)  # Seleccionar todas las columnas excepto la columna 'target'\n","y = Heart['output'] \n","scaler = MinMaxScaler() #Transforma los datos para que se encuentren entre 0 y 1\n","X = scaler.fit_transform(X)\n","# Definir los valores de k\n","k_values = [1, 4, 7]\n","\n","# Inicializar listas para almacenar los valores de las mÃ©tricas para cada valor de k\n","accuracy_k1 = []\n","precision_k1 = []\n","recall_k1 = []\n","f1_k1 = []\n","accuracy_k4 = []\n","precision_k4 = []\n","recall_k4 = []\n","f1_k4 = []\n","accuracy_k7 = []\n","precision_k7 = []\n","recall_k7 = []\n","f1_k7 = []\n","\n","# Definir el objeto StratifiedKFold con 10 pliegues\n","skf = StratifiedKFold(n_splits=10)\n","\n","for train_index, test_index in skf.split(X, y):\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    \n","    # Iterar sobre los valores de k y entrenar un modelo para cada uno\n","    for k in k_values:\n","        # Definir el clasificador KNeighbors con el valor actual de k\n","        knn = KNeighborsClassifier(n_neighbors=k)\n","\n","        # Entrenar el modelo con el conjunto de entrenamiento\n","        knn.fit(X_train, y_train)\n","\n","        # Predecir las etiquetas objetivo del conjunto de prueba\n","        y_pred = knn.predict(X_test)\n","\n","        # Calcular mÃ©tricas de evaluaciÃ³n\n","        accuracy = accuracy_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred, average='macro')\n","        recall = recall_score(y_test, y_pred, average='macro')\n","        f1 = f1_score(y_test, y_pred, average='macro')\n","\n","        # Agregar los valores a las listas correspondientes\n","        if k == 1:\n","            accuracy_k1.append(accuracy)\n","            precision_k1.append(precision)\n","            recall_k1.append(recall)\n","            f1_k1.append(f1)\n","        elif k == 4:\n","            accuracy_k4.append(accuracy)\n","            precision_k4.append(precision)\n","            recall_k4.append(recall)\n","            f1_k4.append(f1)\n","        else:\n","            accuracy_k7.append(accuracy)\n","            precision_k7.append(precision)\n","            recall_k7.append(recall)\n","            f1_k7.append(f1)\n","\n","        # Imprimir resultados\n","        #print(\"-----------Ejecucion:\", i, \"con k =\", k, \"-------------\")\n","        #print(\"Exactitud:\", accuracy)\n","        #print(\"PrecisiÃ³n:\", precision)\n","        #print(\"Sensibilidad:\", recall)\n","        #print(\"F1-score:\", f1)\n","\n","# Calcular los promedios para cada valor de k\n","accuracy_k1_mean = np.mean(accuracy_k1)\n","precision_k1_mean = np.mean(precision_k1)\n","recall_k1_mean = np.mean(recall_k1)\n","f1_k1_mean = np.mean(f1_k1)\n","accuracy_k4_mean = np.mean(accuracy_k4)\n","precision_k4_mean = np.mean(precision_k4)\n","recall_k4_mean = np.mean(recall_k4)\n","f1_k4_mean = np.mean(f1_k4)\n","accuracy_k7_mean = np.mean(accuracy_k7)\n","precision_k7_mean = np.mean(precision_k7)\n","recall_k7_mean = np.mean(recall_k7)\n","f1_k7_mean = np.mean(f1_k7)\n","\n","print(\"----------------Promedios\")\n","print(\"Promedios para k = 1\")\n","print(\"Exactitud:\", accuracy_k1_mean)\n","print(\"PrecisiÃ³n:\", precision_k1_mean)\n","print(\"Sensibilidad:\", recall_k1_mean)\n","print(\"F1-score:\", f1_k1_mean)\n","\n","print(\"Promedios para k = 4\")\n","print(\"Exactitud:\", accuracy_k4_mean)\n","print(\"PrecisiÃ³n:\", precision_k4_mean)\n","print(\"Sensibilidad:\", recall_k4_mean)\n","print(\"F1-score:\", f1_k4_mean)\n","\n","print(\"Promedios para k = 7\")\n","print(\"Exactitud:\", accuracy_k7_mean)\n","print(\"PrecisiÃ³n:\", precision_k7_mean)\n","print(\"Sensibilidad:\", recall_k7_mean)\n","print(\"F1-score:\", f1_k7_mean)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["SE ESCOGIO TRABAJAR CON EL DB AL CUAL SE LE QUITAN LOS DATOS ATIPICOS PERO NO SE NORMALIZA"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Exactitud promedio:  0.8652173913043478\n","PrecisiÃ³n promedio:  0.8733677916286611\n","Sensibilidad promedio:  0.8652173913043478\n","F1-score promedio:  0.8648543504127029\n"]}],"source":["#Clasificador naive bayes\n","from sklearn.naive_bayes import GaussianNB\n","X = data.drop('output', axis=1)  # Seleccionar todas las columnas excepto la columna 'target'\n","y = data['output'] \n","i=0\n","\n","\n","# Inicializar listas para almacenar los valores de las mÃ©tricas para cada valor de k\n","acc_scores = []\n","prec_scores = []\n","rec_scores = []\n","f1_scores = []\n","\n","# Definir el objeto StratifiedKFold con 10 pliegues\n","skf = StratifiedKFold(n_splits=10)\n","\n","for train_index, test_index in skf.split(X, y):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    i=i+1\n","    # Iterar sobre los valores de k y entrenar un modelo para cada uno\n","   \n","    nb_classifier = GaussianNB()\n","\n","        # Entrenar el clasificador en el conjunto de entrenamiento\n","    nb_classifier.fit(X_train, y_train)\n","\n","        # Realizar predicciones en el conjunto de prueba\n","    y_pred = nb_classifier.predict(X_test)\n","\n","\n","    acc_scores.append(accuracy_score(y_test, y_pred))\n","    prec_scores.append(precision_score(y_test, y_pred, average='weighted'))\n","    rec_scores.append(recall_score(y_test, y_pred, average='weighted'))\n","    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n","\n","# Calcular las mÃ©tricas promedio\n","avg_acc = sum(acc_scores) / len(acc_scores)\n","avg_prec = sum(prec_scores) / len(prec_scores)\n","avg_rec = sum(rec_scores) / len(rec_scores)\n","avg_f1 = sum(f1_scores) / len(f1_scores)\n","\n","# Imprimir las mÃ©tricas promedio\n","print(\"Exactitud promedio: \", avg_acc)\n","print(\"PrecisiÃ³n promedio: \", avg_prec)\n","print(\"Sensibilidad promedio: \", avg_rec)\n","print(\"F1-score promedio: \", avg_f1)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------Promedios\n","Promedios para gini\n","Exactitud: 0.8043478260869564\n","PrecisiÃ³n: 0.8064746364746365\n","Sensibilidad: 0.8014277389277389\n","f1-score: 0.8015910551436868\n","Promedios para entropy\n","Exactitud: 0.8130434782608695\n","PrecisiÃ³n: 0.818266317016317\n","Sensibilidad: 0.8095745920745921\n","f1-score: 0.8090488681163739\n","Promedios para log_loss\n","Exactitud: 0.7869565217391304\n","PrecisiÃ³n: 0.7881809856809857\n","Sensibilidad: 0.7858566433566434\n","f1-score: 0.7844722996301944\n"]}],"source":["#Arbol de decision\n","from sklearn.tree import DecisionTreeClassifier\n","X = data.drop('output', axis=1)  # Seleccionar todas las columnas excepto la columna 'target'\n","y = data['output'] \n","# Definir los valores de criterion, se itera!\n","criterion_values = ['gini', 'entropy', 'log_loss']\n","\n","# Inicializar listas para almacenar los valores de las mÃ©tricas para cada valor de criterion\n","accuracy_gini = []\n","precision_gini = []\n","recall_gini = []\n","f1_gini = []\n","accuracy_entropy = []\n","precision_entropy = []\n","recall_entropy = []\n","f1_entropy = []\n","accuracy_log_loss = []\n","precision_log_loss = []\n","recall_log_loss = []\n","f1_log_loss = []\n","\n","# Definir el objeto StratifiedKFold con 10 pliegues\n","skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n","for train_index, test_index in skf.split(X, y):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    i=i+1\n","    for criterion in criterion_values:\n","        # Definir el clasificador DecisionTree con el valor actual de criterion\n","        dtc = DecisionTreeClassifier(criterion=criterion)\n","\n","        # Entrenar el modelo con el conjunto de entrenamiento\n","        dtc.fit(X_train, y_train)\n","\n","        # Predecir las etiquetas objetivo del conjunto de prueba\n","        y_pred = dtc.predict(X_test)\n","\n","        # calcular mÃ©tricas de evaluaciÃ³n\n","        accuracy = accuracy_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred, average='macro')\n","        recall = recall_score(y_test, y_pred, average='macro')\n","        f1 = f1_score(y_test, y_pred, average='macro')\n","\n","        # Agregar los valores a las listas correspondientes\n","        if criterion == 'gini':\n","            accuracy_gini.append(accuracy)\n","            precision_gini.append(precision)\n","            recall_gini.append(recall)\n","            f1_gini.append(f1)\n","        elif criterion == 'entropy':\n","            accuracy_entropy.append(accuracy)\n","            precision_entropy.append(precision)\n","            recall_entropy.append(recall)\n","            f1_entropy.append(f1)\n","        else:\n","            accuracy_log_loss.append(accuracy)\n","            precision_log_loss.append(precision)\n","            recall_log_loss.append(recall)\n","            f1_log_loss.append(f1)\n","\n","        # imprimir resultados\n","        #print(\"-----------Ejecucion:  \",i,\"con criterion=\",criterion,\"-------------\")\n","        #print(\"Exactitud:\", accuracy)\n","        #print(\"PrecisiÃ³n:\", precision)\n","        #print(\"Sensibilidad:\", recall)\n","        #print(\"f1-score:\", f1)\n","\n","# Calcular los promedios para cada valor de criterion\n","accuracy_gini_mean = np.mean(accuracy_gini)\n","precision_gini_mean = np.mean(precision_gini)\n","recall_gini_mean = np.mean(recall_gini)\n","f1_gini_mean = np.mean(f1_gini)\n","#\n","accuracy_entropy_mean = np.mean(accuracy_entropy)\n","precision_entropy_mean = np.mean(precision_entropy)\n","recall_entropy_mean = np.mean(recall_entropy)\n","f1_entropy_mean = np.mean(f1_entropy)\n","#\n","accuracy_log_loss_mean = np.mean(accuracy_log_loss)\n","precision_log_loss_mean = np.mean(precision_log_loss)\n","recall_log_loss_mean = np.mean(recall_log_loss)\n","f1_log_loss_mean = np.mean(f1_log_loss)\n","#IMPRIMIMOS LOS PROMEDIOS\n","print(\"----------------Promedios\")\n","print(\"Promedios para gini\")\n","print(\"Exactitud:\", accuracy_gini_mean)\n","print(\"PrecisiÃ³n:\", precision_gini_mean)\n","print(\"Sensibilidad:\", recall_gini_mean)\n","print(\"f1-score:\", f1_gini_mean)\n","print(\"Promedios para entropy\")\n","print(\"Exactitud:\", accuracy_entropy_mean)\n","print(\"PrecisiÃ³n:\", precision_entropy_mean)\n","print(\"Sensibilidad:\", recall_entropy_mean)\n","print(\"f1-score:\", f1_entropy_mean)\n","print(\"Promedios para log_loss\")\n","print(\"Exactitud:\", accuracy_log_loss_mean)\n","print(\"PrecisiÃ³n:\", precision_log_loss_mean)\n","print(\"Sensibilidad:\", recall_log_loss_mean)\n","print(\"f1-score:\", f1_log_loss_mean)\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Los promedios totales de las metricas son:\n","\n","Promedio Accuracy: 0.8608695652173916\n","Promedio Precision: 0.8710885179635179\n","Promedio Recall: 0.8620221445221447\n","Promedio F1-score: 0.8588619378613275\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}],"source":["#MPL\n","from sklearn.neural_network import MLPClassifier\n","aux = 1\n","X = data.drop('output', axis=1)  # Seleccionar todas las columnas excepto la columna 'target'\n","y = data['output'] \n","# ParÃ¡metros de configuraciÃ³n\n","learning_rates = [0.01, 0.001, 0.0001]\n","hidden_layer_size = 50\n","activation = 'tanh'\n","max_epochs = 200\n","validation_ratio = 0.2\n","# Listas para almacenar las mÃ©tricas de cada iteraciÃ³n\n","accuracies = []\n","precisions = []\n","recalls = []\n","f1_scores = []\n","\n","# Crear una instancia de StratifiedKFold con k = 10\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","for train_index, test_index in skf.split(X, y):\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n","    # Normalizar los datos de entrada (opcional pero recomendado para redes neuronales)\n","    mean = np.mean(X_train, axis=0)\n","    std = np.std(X_train, axis=0)\n","    X_train = (X_train - mean) / std\n","    X_test = (X_test - mean) / std\n","\n","    # Iterar sobre los diferentes valores de learning rate\n","    for learning_rate in learning_rates:\n","        # Crear el clasificador MLP\n","        model = MLPClassifier(hidden_layer_sizes=(hidden_layer_size,),\n","                              activation=activation,\n","                              learning_rate_init=learning_rate,\n","                              solver='adam',\n","                              max_iter=max_epochs,\n","                              validation_fraction=validation_ratio,\n","                              random_state=42)\n","\n","        # Entrenar el modelo\n","        model.fit(X_train, y_train)\n","\n","        # Predecir en el conjunto de prueba\n","        y_pred = model.predict(X_test)\n","\n","        # Calcular las mÃ©tricas del modelo\n","        accuracy = accuracy_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred, average='macro')\n","        recall = recall_score(y_test, y_pred, average='macro')\n","        f1 = f1_score(y_test, y_pred, average='macro')\n","\n","        # Almacenar las mÃ©tricas en las listas\n","        accuracies.append(accuracy)\n","        precisions.append(precision)\n","        recalls.append(recall)\n","        f1_scores.append(f1)\n","        #print(f\"Promedios utilizando el learning rate: {learning_rate} en el fold: {aux}\")\n","        #print(f\"Promedio Accuracy: {accuracy}\")\n","        #print(f\"Promedio Precision: {precision}\")\n","        #print(f\"Promedio Recall: {recall}\")\n","        #print(f\"Promedio F1-score: {f1}\")\n","    aux = aux +1\n","    # Calcular las mÃ©tricas promedios totales\n","avg_accuracy = np.mean(accuracies)\n","avg_precision = np.mean(precisions)\n","avg_recall = np.mean(recalls)\n","avg_f1 = np.mean(f1_scores)\n","\n","# Imprimir las mÃ©tricas promedio\n","print(\"Los promedios totales de las metricas son:\\n\")\n","print(f\"Promedio Accuracy: {avg_accuracy}\")\n","print(f\"Promedio Precision: {avg_precision}\")\n","print(f\"Promedio Recall: {avg_recall}\")\n","print(f\"Promedio F1-score: {avg_f1}\")\n","    \n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
